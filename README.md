# ML-Exercises

This repository contains various Machine Learning Exercises I completed as a part of my Master's in Data Science program.

## Exercise 1:
Exercise 1 involves three datasets: 
  1. Fires in Space dataset (fire_archive_V1_96617.csv):

    https://www.kaggle.com/datasets/carlosparadis/fires-from-space-australia-and-new-zeland
  Performed preliminary data exploration and visualization tasks. 
  
  2. House Price Prediction:

    https://www.kaggle.com/datasets/shree1992/housedata
  Data preprocessing, cleaning, handling of outliers, and regression analysis (Linear Regression, Ridge, Lasso, and Elastic Net) for the purpose of predicting housing prices. 

  3. Credit-G dataset:

    https://www.openml.org/search?type=data&sort=runs&id=31&status=active
  Executed comprehensive classification analysis (Logistic Regression, Linear Support Vector Machines, and K Nearest Neighbors) for the purpose of classifying potential credit risks. 

## Exercise 2:
Exercise 2 involves two datasets: 
  1. Used Car Price Prediction:

    https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data
  Feature selection, feature engineering, preprocessing, data cleaning, and regression analysis for the purpose of predicting used car prices.
  
  2. Wisconsin Breast Cancer Diagnostics:

    https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic
  Implementation of K-Means clustering algorithm from scratch (without using the sklearn package) for the purpose of diagnosing breast cancer images. 

## Exercise 3: 
Exercise 3 involves two sub-exercises: 
  1. Exploration of the bias / variance tradeoff using randomly generated numpy data. Trained several polynomial models of varying degrees to compare performance.
  
  2. 20 Newsgroups Dataset:

    http://qwone.com/~jason/20Newsgroups/
  Implementation of Naive Bayes and Logistic Regression models from scratch (without using sklearn packages). Model comparison between generatative and discrimanative models for the purpose of text classification.

  ## Exercise 4: 
  Exercise 4 involves implementation of AdaBoost and Bagging algorithms from scratch (without using sklearn packages) for the purpose of classification tasks on three different datasets:
  1. Letter Recognition Dataset:

    https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data
  
  2. German Credit Dataset:

    https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data

  3. Spambase Email Classification Dataset

    https://archive.ics.uci.edu/dataset/94/spambase

## More detailed descriptions and comments for each exercise are found within the respective jupyter notebooks. 




